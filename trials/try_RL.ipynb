{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chess\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_board_vector(board, flip=False):\n",
    "    vec = np.zeros((64,), dtype=\"float32\")\n",
    "    curr_player = board.turn\n",
    "    flip_mult = 1 if not flip else -1\n",
    "    for pos in range(64):\n",
    "        piece = board.piece_at(pos)\n",
    "        if piece:\n",
    "            if piece.color == curr_player:\n",
    "                piece_mult = 1\n",
    "            else:\n",
    "                piece_mult = -1\n",
    "            vec[pos] = flip_mult*piece_mult*int(piece.piece_type)\n",
    "    return vec\n",
    "\n",
    "\n",
    "def make_move(board, move, piece_value_map, promotion_value_map):\n",
    "    \"\"\"Return a new board vector and reward and whether it finishes the game\n",
    "    Assume the move is already validated and legal\"\"\"\n",
    "    reward = 0\n",
    "    done = False\n",
    "    init_pos, new_pos, promotion = move[:2], move[2:4], move[4:5]\n",
    "    if board.piece_at(chess.SQUARE_NAMES.index(new_pos)):\n",
    "        reward += piece_value_map[board.piece_at(\n",
    "            chess.SQUARE_NAMES.index(new_pos)).piece_type]\n",
    "    if promotion:\n",
    "        reward += promotion_value_map[promotion]\n",
    "    board.push(chess.Move.from_uci(move))\n",
    "    new_state = get_board_vector(board, flip=True)\n",
    "    if board.is_game_over():\n",
    "        done = True\n",
    "    return new_state, reward, done\n",
    "\n",
    "def neural_network_model(input_size, output_size, learning_rate=.0001):\n",
    "    network = input_data(shape=[None, input_size], name='input')\n",
    "    network = fully_connected(network, 128, activation='relu')\n",
    "    network = fully_connected(network, 128, activation='relu')\n",
    "    network = fully_connected(network, output_size, activation='softmax')\n",
    "    network = regression(network, optimizer='adam', learning_rate=learning_rate,\n",
    "                         loss='mean_square', name='targets')\n",
    "    model = tflearn.DNN(network, tensorboard_dir='log')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_turn(model):\n",
    "    board_vec = get_board_vector(board)\n",
    "    action_ls = model.predict(board_vec.reshape(1, -1))[0]\n",
    "    sorted_indicies = np.flip(np.argsort(action_ls))\n",
    "    move = None\n",
    "    curr_ind = 0\n",
    "    while not move:\n",
    "        move = chess.Move.from_uci(action_map[str(sorted_indicies[curr_ind])])\n",
    "        if move not in board.legal_moves:\n",
    "            curr_ind += 1\n",
    "            move = None\n",
    "    board.push(move)\n",
    "    print(\"Move Rank: \", curr_ind)\n",
    "    \n",
    "def player_turn(move_string):\n",
    "    board.push(chess.Move.from_uci(move_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../action_map.json') as fp:\n",
    "    action_map = json.load(fp)\n",
    "trained_model = neural_network_model(input_size=64,\n",
    "                                  output_size=len(action_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = chess.Board()\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "player_turn('e2e4')\n",
    "model_turn(trained_model)\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
